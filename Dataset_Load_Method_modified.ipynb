{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset_Load_Method_modified.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangmin213/DialectClassification/blob/main/Dataset_Load_Method_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wLgVPWZzuJL",
        "outputId": "265202da-fee3-4921-9ad6-67bdf56595e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "import os\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Subset"
      ],
      "metadata": {
        "id": "VtM_DqZDvMla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2region={0:'gangwon', 1:'gyeongsang', 2:'jeonla', 3:'chungcheong', 4:'jeju'}\n",
        "region2index = {v:k for k,v in index2region.items()}\n",
        "region_shortening = ['GW','GS','JL','CC','JJ']\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "PUcj5NFYvOkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 셋 구성 (full dataset)\n",
        "dataset_dir = '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/'"
      ],
      "metadata": {
        "id": "IUgYpMhQvPjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in index2region.items():\n",
        "    exec(f\"{v}_dirs = glob(dataset_dir+'*_{v}/*')\")\n",
        "jeonla_dirs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QVZzetDvb3Y",
        "outputId": "f87e2b47-9150-4a3d-d1de-49bc34a91eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000018',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000027',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000012',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000032',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000005',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000014',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000006',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000019',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000024',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000015']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존의 pickle 파일을 낱개로 쪼개는 함수\n",
        "def make_tuple_data(idx,dirs, max_num):\n",
        "    y=[0,0,0,0,0]\n",
        "    y[idx]=1\n",
        "    listIDs=[] # 파일 명 저장하는 리스트\n",
        "    for i, region_dir in enumerate(dirs):\n",
        "        if i>=max_num:break\n",
        "        spectro_path = glob(region_dir+'/*_spectro.pickle')[0]\n",
        "        mfcc_path = glob(region_dir+'/*_mfcc.pickle')[0]\n",
        "        chroma_path = glob(region_dir+'/*_chroma.pickle')[0]\n",
        "        \n",
        "        with open(spectro_path, \"rb\") as f:\n",
        "            spectro = pickle.load(f)\n",
        "        with open(mfcc_path, \"rb\") as f:\n",
        "            mfcc = pickle.load(f)\n",
        "        with open(chroma_path, \"rb\") as f:\n",
        "            chroma = pickle.load(f)\n",
        "\n",
        "        tuple_data=(spectro,mfcc,chroma)\n",
        "        region=index2region[idx]\n",
        "        \n",
        "        # 낱개로 쪼개서 pickle로 다시 저장\n",
        "        for index,data in enumerate(spectro):\n",
        "            listIDs.append(f\"{region}_{i}_{index}.pickle\")\n",
        "            with open(f\"/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/tuple_data/{region}_{i}_{index}.pickle\",\"wb\") as f:\n",
        "                pickle.dump(((spectro[index],mfcc[index],chroma[index]),y),f)\n",
        "        \n",
        "    print(f\"{region} data number:\",len(listIDs))\n",
        "    return listIDs\n",
        "\n",
        "def make_tuple(max_num=2):\n",
        "    listIDs=[]\n",
        "    listIDs += make_tuple_data(region2index['jeonla'],jeonla_dirs, max_num)\n",
        "    listIDs += make_tuple_data(region2index['chungcheong'],chungcheong_dirs, max_num)\n",
        "    listIDs += make_tuple_data(region2index['gyeongsang'],gyeongsang_dirs, max_num)\n",
        "    listIDs += make_tuple_data(region2index['jeju'],jeju_dirs, max_num)\n",
        "    listIDs += make_tuple_data(region2index['gangwon'],gangwon_dirs, max_num)\n",
        "    return listIDs\n",
        "\n",
        "listIDs = make_tuple(1000) # listIDs에는 모든 파일 명이 저장됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "4rPtKfgBvdkR",
        "outputId": "d3e820d1-5423-40a6-bf41-af5b39444169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jeonla data number: 913\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2bb28a76d9c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{region} spec shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mlistIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m# jeonla_data, chungcheong_data, gyeongsang_data, jeju_data, gangwon_data = make_tuple(1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# print_data(jeonla_data, 'jeonla')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-2bb28a76d9c8>\u001b[0m in \u001b[0;36mmake_tuple\u001b[0;34m(max_num)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mlistIDs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlistIDs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmake_tuple_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jeonla'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjeonla_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mlistIDs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmake_tuple_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chungcheong'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchungcheong_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mlistIDs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmake_tuple_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gyeongsang'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgyeongsang_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlistIDs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmake_tuple_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jeju'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjeju_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-2bb28a76d9c8>\u001b[0m in \u001b[0;36mmake_tuple_data\u001b[0;34m(idx, dirs, max_num)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mspectro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchroma_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mchroma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일부러 끊었음"
      ],
      "metadata": {
        "id": "ahbNl42fBpf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "class MultiModalDataset(Dataset):\n",
        "\n",
        "    def __init__(self, list_IDs, path):\n",
        "        self.list_IDs=list_IDs # ID = file name\n",
        "        self.path=path # data directory\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_name = self.list_IDs[idx] # 인덱스에 맞는 파일명 확인\n",
        "        with open(path+file_name,\"rb\") as f: # 해당 파일 불러오기\n",
        "            file=pickle.load(f)\n",
        "        datas, label = file\n",
        "        spec, mfcc, chroma = datas\n",
        "        spec, mfcc, chroma = normalize(spec), normalize(mfcc), normalize(chroma)\n",
        "        spec, mfcc, chroma = torch.tensor(spec, dtype=torch.float32), torch.tensor(mfcc, dtype=torch.float32), torch.tensor(chroma, dtype=torch.float32)\n",
        "        spec, mfcc, chroma = spec.unsqueeze(0), mfcc.unsqueeze(0), chroma.unsqueeze(0)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "        data = (spec, mfcc, chroma)\n",
        "        return data, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.list_IDs)"
      ],
      "metadata": {
        "id": "0dZGViQC2qhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/tuple_data/\"\n",
        "dataset=MultiModalDataset(listIDs,path) # 데이터셋 선언\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwiXoTx374vA",
        "outputId": "5cc30ec4-b1a1-4215-e787-849debc259f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "913"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self,input_channel, output_channel, kernel_size, stride=1, padding=0):\n",
        "        super(Block,self).__init__()\n",
        "\n",
        "        self.conv1=nn.Conv2d(input_channel,output_channel,kernel_size=kernel_size,padding=padding) # no stride\n",
        "        self.conv2=nn.Conv2d(output_channel,output_channel,kernel_size=kernel_size,stride=stride,padding=padding) # stride if down sampling\n",
        "        self.bn=nn.BatchNorm2d(output_channel)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "        self.layer=nn.Sequential(self.conv1, self.bn, self.relu, self.conv2, self.bn)\n",
        "\n",
        "        self.stride=stride\n",
        "        self.iden = nn.Conv2d(input_channel, output_channel, kernel_size=(1,1), stride=1)\n",
        "        if input_channel==64:\n",
        "            self.iden = nn.Conv2d(input_channel, output_channel, kernel_size=(1,1), stride=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        y = self.layer(x)\n",
        "        if self.stride==1: # stride==2 인 경우는 downsampling 구간이기 때문에 residual 안함\n",
        "            y = y + self.iden(x)\n",
        "        y = self.relu(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "mMNla6Ef8V0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self,data_type=\"mfcc\",method=\"origin\",best_model_save_path=\"./LeNet_best_model.pt\"):\n",
        "        super(LeNet,self).__init__()\n",
        "        \n",
        "        self.best_model_save_path = best_model_save_path\n",
        "        self.data_type=data_type\n",
        "        self.method=method\n",
        "\n",
        "        if data_type==\"mfcc\": # (1,100,501)\n",
        "            self.conv1=nn.Conv2d(1,64,kernel_size=(6,7),stride=2,padding=3)\n",
        "        elif data_type==\"spec\": #(1,201,501)\n",
        "            self.conv1=nn.Conv2d(1,64,kernel_size=(7,7),stride=2,padding=3)\n",
        "        elif data_type==\"chroma\": #(1,12,501)\n",
        "            self.conv1=nn.Conv2d(1,64,kernel_size=(6,7),stride=1,padding=3)\n",
        "        self.maxpool=nn.MaxPool2d(kernel_size=(3,3),stride=2,padding=1)\n",
        "        self.avgpool=nn.AdaptiveAvgPool2d((1,1)) # global avg pool\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "        self.seq1=nn.Sequential(self.conv1,self.relu,self.maxpool)  # (1,100,501)/(1,12,501)/(1,201,501) -> (64,51,251)/(1,13,251)/(1,101,251).conv -> (64,25,126)/(64,7,126)/(64,51,126).maxpool\n",
        "        self.seq2=nn.Sequential(Block(64,64,(3,3),padding=1),Block(64,64,(3,3),padding=1),Block(64,128,(3,4),stride=2,padding=1)) # (64,25,126) -> (64,25,126).block -> (64,25,126).block -> (128,13,63)/(128,4,63)/(128,26,63).block \n",
        "        if data_type==\"mfcc\":\n",
        "            self.seq3=nn.Sequential(Block(128,128,(3,3),padding=1),Block(128,128,(3,3),padding=1),Block(128,256,(3,3),stride=2,padding=1)) # (128,13,63) -> (128,13,63).block -> (128,13,63).block -> (256,7,32).block \n",
        "        elif data_type==\"spec\":\n",
        "            self.seq3=nn.Sequential(Block(128,128,(3,3),padding=1),Block(128,128,(3,3),padding=1),Block(128,256,(4,3),stride=2,padding=1)) # (128,26,63) -> ... -> (256,12,32).block \n",
        "        elif data_type==\"chroma\":\n",
        "            self.seq3=nn.Sequential(Block(128,128,(3,3),padding=1),Block(128,128,(3,3),padding=1),Block(128,256,(2,3),stride=2,padding=1)) # (128,4,63)/(128,26,63) -> ... -> (256,2,32)/(256,13,32).block \n",
        "        self.seq4=nn.Sequential(Block(256,256,(3,3),padding=1),Block(256,256,(3,3),padding=1),self.avgpool) # ... -> (256,1,1).avgpool\n",
        "\n",
        "        if self.method==\"multimodal\":\n",
        "            self.fc=nn.Linear(256,256)\n",
        "        if self.method==\"origin\":\n",
        "            self.fc=nn.Linear(256,5)\n",
        "            self.loss=nn.CrossEntropyLoss()\n",
        "            self.optimizer=optim.Adam(self.parameters(),lr=0.0001)\n",
        "\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def forward(self,x):       \n",
        "        y=self.seq1(x)\n",
        "        y=self.seq2(y)\n",
        "        y=self.seq3(y)\n",
        "        y=self.seq4(y)\n",
        "        y=y.view(y.shape[0],-1)\n",
        "        y=self.fc(y)\n",
        "        return y\n",
        "\n",
        "    def train_(self, train_loader, val_loader, learning_rate, epochs, device):\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "        self.pred_labels_train = []\n",
        "        self.real_labels_train = []\n",
        "        self.pred_labels_val = None\n",
        "        self.real_labels_val = None\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        self.loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "        best_epoch = -1\n",
        "        best_acc = -1 \n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            start_time = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            epoch_acc = 0.0\n",
        "            self.train()\n",
        "\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(train_loader)):\n",
        "                \n",
        "                spec, mfcc, chroma = batch_data\n",
        "\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                \n",
        "                batch_label = batch_label.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                pred = self.forward(batch_data) # (batch_size, 5)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                total += batch_data.shape[0]\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                correct += pred_indices.eq(batch_label).sum().item()\n",
        "                \n",
        "                if epoch==epochs: #last epoch\n",
        "                    self.pred_labels_train.append(pred_indices)\n",
        "                    self.real_labels_train.append(batch_label)\n",
        "                #for p, l in zip(pred_indices, batch_label):\n",
        "                #    print(f\"predicted: {index2region[p.item()]} real:{index2region[l.item()]}\")\n",
        "            \n",
        "            end_time = time.time()\n",
        "            print(f\"epoch {epoch} time: {end_time-start_time}sec(s).\")\n",
        "            \n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            epoch_acc = correct / total\n",
        "            self.train_accuracy.append(epoch_acc)\n",
        "            print(f\"epoch {epoch} train accuracy: {epoch_acc}\")\n",
        "            print(f\"epoch {epoch} loss: {epoch_loss}\")  \n",
        "\n",
        "\n",
        "            predicted, labels, val_loss = self.predict(val_loader, device)\n",
        "            if epoch==epochs: #last epoch\n",
        "                self.pred_labels_val=predicted.cpu().numpy()\n",
        "                self.real_labels_val=labels.cpu().numpy()\n",
        "            val_acc = predicted.eq(labels).sum().item() / len(predicted)\n",
        "            print(f\"epoch {epoch} val accuracy: {val_acc}\")\n",
        "            print(f\"epoch {epoch} val loss: {val_loss}\")\n",
        "\n",
        "            if val_acc > epoch_acc:\n",
        "                best_acc = val_acc\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), self.best_model_save_path)\n",
        "            \n",
        "            self.val_accuracy.append(val_acc)\n",
        "            self.val_loss.append(val_loss)\n",
        "        \n",
        "        self.pred_labels_train = torch.cat(self.pred_labels_train, dim=0)\n",
        "        self.real_labels_train = torch.cat(self.real_labels_train, dim=0)\n",
        "        self.pred_labels_train = self.pred_labels_train.cpu().numpy()\n",
        "        self.real_labels_train = self.real_labels_train.cpu().numpy()\n",
        "            \n",
        "            \n",
        "            \n",
        "        print(\"Finish!\")\n",
        "        \n",
        "        return best_acc, best_epoch\n",
        "            \n",
        "    def predict(self, test_loader, device):\n",
        "        self.eval()\n",
        "        labels = []\n",
        "        predicted = []\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "                spec, mfcc, chroma = batch_data\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                batch_label = batch_label.to(device)\n",
        "                \n",
        "                pred = self.forward(batch_data)\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted.append(pred_indices)\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                labels.append(batch_label)\n",
        "        val_loss /= len(test_loader)\n",
        "        predicted = torch.cat(predicted, dim=0)\n",
        "        labels = torch.cat(labels, dim=0)\n",
        "\n",
        "        return predicted, labels, val_loss\n",
        "    \n",
        "    def plot(self, which):\n",
        "        \n",
        "        X = [i for i in range(1, len(self.train_accuracy) + 1)]\n",
        "        if which=='train_loss':\n",
        "            y = self.train_loss\n",
        "        elif which=='train_acc':\n",
        "            y = self.train_accuracy\n",
        "        elif which=='val_acc':\n",
        "            y = self.val_accuracy\n",
        "        elif which=='val_loss':\n",
        "            y = self.val_loss\n",
        "        elif which=='confusion_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening)\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return        \n",
        "        elif which=='confusion_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening)\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return   \n",
        "            \n",
        "\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(which)\n",
        "        plt.title(which)\n",
        "        plt.plot(X, y, label=\"Train loss\")\n",
        "        plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "YEn19l1Q8awz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CV_Plot(title, arg, y):\n",
        "        X = [i for i in range(1, len(y) + 1)]\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(title)\n",
        "        plt.title(title)\n",
        "        plt.plot(X, y, label=title)\n",
        "        plt.savefig(f\"./result/model_{title}_{arg}.png\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "wGPZ-Ec18jCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CrossValidation(dataset, learning_rate, epochs, device, method = \"ResNet\",data_type=\"mfcc\"):\n",
        "        hparams = []\n",
        "        for i in range(len(learning_rate)):\n",
        "            for j in range(len(epochs)):\n",
        "                hparams.append((learning_rate[i], epochs[j]))\n",
        "        print(hparams)\n",
        "\n",
        "        train_dataset_l = []\n",
        "        validation_dataset_l = []\n",
        "\n",
        "        kf = KFold(n_splits = 5, shuffle = True, random_state = 50)\n",
        "\n",
        "        for train_index, test_index in kf.split(train_dataset):\n",
        "            train_dataset_l.append(Subset(train_dataset,train_index))\n",
        "            validation_dataset_l.append(Subset(train_dataset,test_index))\n",
        "\n",
        "        result = []\n",
        "        for i in range(len(hparams)):\n",
        "            lr = hparams[i][0]\n",
        "            e = hparams[i][1]\n",
        "\n",
        "            print(f\"Learning rate : {lr}, Epochs : {e}\")\n",
        "\n",
        "            last_val_acc = []\n",
        "            for j in range(5):\n",
        "                print(f\"#{j+1} validation\")\n",
        "                if method==\"Multimodal_ResNet\":\n",
        "                    model = MultiModalDialectClassifier(method=\"ResNet\").to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"Multimodal_LeNet\":\n",
        "                    model = MultiModalDialectClassifier(method=\"LeNet\").to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"ResNet\":\n",
        "                    model = ResNet18(1,output_dim=5,model_type=data_type).to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"LeNet\":\n",
        "                    model = LeNet(data_type=data_type).to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"LSTM\":\n",
        "                    model = LSTM(data_type=data_type).to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                train_loader = DataLoader(train_dataset_l[j], batch_size=32, shuffle=True)\n",
        "                validation_loader = DataLoader(validation_dataset_l[j], batch_size=32, shuffle=True)\n",
        "\n",
        "                model.train_(train_loader, validation_loader, lr, e, device)\n",
        "                last_val_acc.append(model.val_accuracy[-1])\n",
        "                    \n",
        "                # model.plot('train_acc')\n",
        "                # model.plot('val_acc')\n",
        "            result.append((np.array(last_val_acc)).mean())\n",
        "\n",
        "        idx = result.index(max(result))\n",
        "        best_lr, best_ep = hparams[idx]\n",
        "        print(f\"Best Learning Rate : {best_lr}, Best Epoch : {best_ep}\")\n",
        "\n",
        "        return best_lr, best_ep"
      ],
      "metadata": {
        "id": "iHywBEh38rKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(dataset)*0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "GPaHo4Yk807r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = [0.0001, 0.0005, 0.001]\n",
        "ep = [30]\n",
        "\n",
        "result = CrossValidation(train_dataset, learning_rate= lr, epochs= ep, device = device, method = \"LeNet\",data_type=\"mfcc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "fbGCLMUf85gq",
        "outputId": "ff258ffa-c1da-4180-e863-66de4e5d50b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0001, 30), (0.0005, 30), (0.001, 30)]\n",
            "Learning rate : 0.0001, Epochs : 30\n",
            "#1 validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [03:19<00:00, 10.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 time: 199.16643905639648sec(s).\n",
            "epoch 1 train accuracy: 0.958904109589041\n",
            "epoch 1 loss: 0.5163380017406062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 val accuracy: 1.0\n",
            "epoch 1 val loss: 0.4467105448246002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-3a54e84a43d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LeNet\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mfcc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-1fa15f37c4f3>\u001b[0m in \u001b[0;36mCrossValidation\u001b[0;34m(dataset, learning_rate, epochs, device, method, data_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mvalidation_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mlast_val_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-050effd40523>\u001b[0m in \u001b[0;36mtrain_\u001b[0;34m(self, train_loader, val_loader, learning_rate, epochs, device)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, 5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-050effd40523>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7d21c8c80467>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# stride==2 인 경우는 downsampling 구간이기 때문에 residual 안함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일부러 끊었음"
      ],
      "metadata": {
        "id": "PN0VCH6DBtnS"
      }
    }
  ]
}