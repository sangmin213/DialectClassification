{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangmin213/DialectClassification/blob/main/model_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6dWD-3imYrX",
        "outputId": "779f9af7-6d51-4474-ded4-2e5c12222b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "i7GkRqXfWRJn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wra64zxl7iL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "import os\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji84avrSl7iU"
      },
      "outputs": [],
      "source": [
        "index2region={0:'gangwon', 1:'gyeongsang', 2:'jeonla', 3:'chungcheong', 4:'jeju'}\n",
        "region2index = {v:k for k,v in index2region.items()}\n",
        "region_shortening = ['GW','GS','JL','CC','JJ']\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6HhqTPMl7iW"
      },
      "outputs": [],
      "source": [
        "# 데이터 셋 구성 (full dataset)\n",
        "dataset_dir = '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FORl3wxvl7iY",
        "outputId": "91cd898e-daef-4c5e-8f4c-fc0e8dd9d96d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "region_dir = glob(dataset_dir)\n",
        "region_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDWQjpRdl7ia",
        "outputId": "6777b15f-5fb5-4eb7-c7e8-ab95a120419c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000018',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000027',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000012',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000032',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000005',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000014',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000006',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000019',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000024',\n",
              " '/content/drive/MyDrive/인공지능_프로젝트_Team_12/데이터/small_dataset/preprocessed_jeonla/DJDD20000015']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "for k, v in index2region.items():\n",
        "    exec(f\"{v}_dirs = glob(dataset_dir+'*_{v}/*')\")\n",
        "jeonla_dirs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GthfMgZl7ib",
        "outputId": "84586e15-2920-4fc9-a763-e4d8f4b3a54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jeonla data num:  913\n",
            "jeonla tuple size 3\n",
            "jeonla spec shape (201, 501)\n",
            "chungcheong data num:  1108\n",
            "chungcheong tuple size 3\n",
            "chungcheong spec shape (201, 501)\n",
            "gyeongsang data num:  842\n",
            "gyeongsang tuple size 3\n",
            "gyeongsang spec shape (201, 501)\n",
            "jeju data num:  756\n",
            "jeju tuple size 3\n",
            "jeju spec shape (201, 501)\n",
            "gangwon data num:  1183\n",
            "gangwon tuple size 3\n",
            "gangwon spec shape (201, 501)\n"
          ]
        }
      ],
      "source": [
        "def make_tuple_data(dirs, max_num):\n",
        "    for i, region_dir in enumerate(dirs):\n",
        "        if i>=max_num:break\n",
        "        spectro_path = glob(region_dir+'/*_spectro.pickle')[0]\n",
        "        mfcc_path = glob(region_dir+'/*_mfcc.pickle')[0]\n",
        "        chroma_path = glob(region_dir+'/*_chroma.pickle')[0]\n",
        "        \n",
        "        with open(spectro_path, \"rb\") as f:\n",
        "            spectro = pickle.load(f)\n",
        "        with open(mfcc_path, \"rb\") as f:\n",
        "            mfcc = pickle.load(f)\n",
        "        with open(chroma_path, \"rb\") as f:\n",
        "            chroma = pickle.load(f)\n",
        "\n",
        "        if i == 0:\n",
        "            spectro_data = spectro\n",
        "            mfcc_data = mfcc\n",
        "            chroma_data = chroma\n",
        "        else:\n",
        "            spectro_data = np.concatenate([spectro_data,spectro], axis=0)\n",
        "            mfcc_data = np.concatenate([mfcc_data,mfcc], axis=0)\n",
        "            chroma_data = np.concatenate([chroma_data,chroma], axis=0)\n",
        "    if max_num ==0:return []\n",
        "        \n",
        "    r_data = [(s,m,c) for s,m,c in zip(spectro_data,mfcc_data,chroma_data)]\n",
        "        \n",
        "    return r_data\n",
        "\n",
        "def make_tuple(max_num=2):\n",
        "    jeonla_data = make_tuple_data(jeonla_dirs, max_num)\n",
        "    chungcheong_data = make_tuple_data(chungcheong_dirs, max_num)\n",
        "    gyeongsang_data = make_tuple_data(gyeongsang_dirs, max_num)\n",
        "    jeju_data = make_tuple_data(jeju_dirs, max_num)\n",
        "    gangwon_data = make_tuple_data(gangwon_dirs, max_num)\n",
        "    return jeonla_data, chungcheong_data, gyeongsang_data, jeju_data, gangwon_data\n",
        "\n",
        "def print_data(r_data, region):\n",
        "    if len(r_data)==0: return\n",
        "    print(f\"{region} data num: \", len(r_data))\n",
        "    print(f\"{region} tuple size\", len(r_data[0]))\n",
        "    print(f\"{region} spec shape\", r_data[0][0].shape)\n",
        "\n",
        "jeonla_data, chungcheong_data, gyeongsang_data, jeju_data, gangwon_data = make_tuple(1000)\n",
        "print_data(jeonla_data, 'jeonla')\n",
        "print_data(chungcheong_data, 'chungcheong')\n",
        "print_data(gyeongsang_data, 'gyeongsang')\n",
        "print_data(jeju_data, 'jeju')\n",
        "print_data(gangwon_data, 'gangwon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLvj5Nd7l7ih"
      },
      "outputs": [],
      "source": [
        "jeonla_data_l = []\n",
        "for data in jeonla_data:\n",
        "    y = [0,0,0,0,0]\n",
        "    y[region2index['jeonla']] = 1\n",
        "    jeonla_data_l.append((data,y))\n",
        "\n",
        "chungcheong_data_l = []\n",
        "for data in chungcheong_data:\n",
        "    y = [0,0,0,0,0]\n",
        "    y[region2index['chungcheong']] = 1\n",
        "    chungcheong_data_l.append((data,y))\n",
        "\n",
        "gyeongsang_data_l = []\n",
        "for data in gyeongsang_data:\n",
        "    y = [0,0,0,0,0]\n",
        "    y[region2index['gyeongsang']] = 1\n",
        "    gyeongsang_data_l.append((data,y))\n",
        "\n",
        "jeju_data_l = []\n",
        "for data in jeju_data:\n",
        "    y = [0,0,0,0,0]\n",
        "    y[region2index['jeju']] = 1\n",
        "    jeju_data_l.append((data,y))\n",
        "\n",
        "gangwon_data_l = []\n",
        "for data in gangwon_data:\n",
        "    y = [0,0,0,0,0]\n",
        "    y[region2index['gangwon']] = 1\n",
        "    gangwon_data_l.append((data,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7V0oi-pl7il",
        "outputId": "a13ed48f-7b48-42bd-a248-608560d83892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "datasumup = np.concatenate([jeonla_data_l[:500], chungcheong_data_l[:500], gangwon_data_l[:500], jeju_data_l[:500], gyeongsang_data_l[:500]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK9vpGjjl7in"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "class MultiModalDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        datas, label = self.data[idx]\n",
        "        spec, mfcc, chroma = datas\n",
        "        spec, mfcc, chroma = normalize(spec), normalize(mfcc), normalize(chroma)\n",
        "        spec, mfcc, chroma = torch.tensor(spec, dtype=torch.float32), torch.tensor(mfcc, dtype=torch.float32), torch.tensor(chroma, dtype=torch.float32)\n",
        "        spec, mfcc, chroma = spec.unsqueeze(0), mfcc.unsqueeze(0), chroma.unsqueeze(0)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "        data = (spec, mfcc, chroma)\n",
        "        return data, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofR5mcv9l7ip",
        "outputId": "494c25e4-2211-4007-be09-295cd194a6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset = MultiModalDataset(datasumup)\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "8hi2dX2fWVL2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfbSD65nl7ir"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3,3), stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.seq1 = nn.Sequential(self.conv1, self.bn1, self.relu)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3,3), stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.seq2 = nn.Sequential(self.conv2, self.bn2)\n",
        "        \n",
        "        self.down_flag = False\n",
        "        if in_channels != out_channels: self.down_flag = True\n",
        "\n",
        "        self.downsample = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1,1), stride=2, padding=0, bias=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        y = self.seq1(x)\n",
        "        #print(y.shape)\n",
        "        y = self.seq2(y)\n",
        "        #print(y.shape)\n",
        "\n",
        "        if self.down_flag:\n",
        "            x = self.downsample(x)\n",
        "        \n",
        "        y = self.relu(y)\n",
        "        #print(x.shape)\n",
        "        #print(y.shape)\n",
        "        y = y + x\n",
        "\n",
        "        return y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3oe1QSVl7is"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, output_dim=256, model_type='spec',best_model_save_path=\"./ResNet_best_model.pt\"):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        self.best_model_save_path = best_model_save_path\n",
        "        self.data_type = model_type\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=(7,7), stride=2, padding=3)\n",
        "        self.BN1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3,3), stride=2, padding=1)\n",
        "\n",
        "        self.seq1 = nn.Sequential(self.conv1, self.BN1, self.pool1)\n",
        "\n",
        "        self.seq2 = nn.Sequential(BasicBlock(64,64), BasicBlock(64,64))\n",
        "        self.seq3 = nn.Sequential(BasicBlock(64,64), BasicBlock(64, 128, stride=2))\n",
        "        self.seq4 = nn.Sequential(BasicBlock(128,128), BasicBlock(128,128))\n",
        "        self.seq5 = nn.Sequential(BasicBlock(128,128), BasicBlock(128,256,stride=2))\n",
        "\n",
        "        self.avg_pool1 = nn.AdaptiveAvgPool2d((1,1))\n",
        "        # if model_type=='spec':\n",
        "        #     self.fc1 = nn.Linear(256*13*32, output_dim)\n",
        "        # elif model_type=='mfcc':\n",
        "        #     self.fc1 = nn.Linear(256*7*32, output_dim)\n",
        "        # elif model_type=='chroma':\n",
        "        #     self.fc1 = nn.Linear(256*1*32, output_dim)\n",
        "        self.fc1 = nn.Linear(256, output_dim)\n",
        "\n",
        "\n",
        "        self.lastlayer = nn.Sequential(self.fc1, self.relu)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.seq1(x)\n",
        "        y = self.seq2(y)\n",
        "        y = self.seq3(y)\n",
        "        y = self.seq4(y)\n",
        "        y = self.seq5(y)\n",
        "        y = self.avg_pool1(y)\n",
        "        y = y.view(y.shape[0],-1)\n",
        "        y = self.lastlayer(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def train_(self, train_loader, val_loader, learning_rate, epochs, device):\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "        self.pred_labels_train = []\n",
        "        self.real_labels_train = []\n",
        "        self.pred_labels_val = None\n",
        "        self.real_labels_val = None\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        self.loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "        best_epoch = -1\n",
        "        best_acc = -1 \n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            start_time = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            epoch_acc = 0.0\n",
        "            self.train()\n",
        "\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(train_loader)):\n",
        "                \n",
        "                spec, mfcc, chroma = batch_data\n",
        "\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                \n",
        "                batch_label = batch_label.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                pred = self.forward(batch_data) # (batch_size, 5)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                total += batch_data.shape[0]\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                correct += pred_indices.eq(batch_label).sum().item()\n",
        "                \n",
        "                if epoch==epochs: #last epoch\n",
        "                    self.pred_labels_train.append(pred_indices)\n",
        "                    self.real_labels_train.append(batch_label)\n",
        "                #for p, l in zip(pred_indices, batch_label):\n",
        "                #    print(f\"predicted: {index2region[p.item()]} real:{index2region[l.item()]}\")\n",
        "            \n",
        "            end_time = time.time()\n",
        "            print(f\"epoch {epoch} time: {end_time-start_time}sec(s).\")\n",
        "            \n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            epoch_acc = correct / total\n",
        "            self.train_accuracy.append(epoch_acc)\n",
        "            print(f\"epoch {epoch} train accuracy: {epoch_acc}\")\n",
        "            print(f\"epoch {epoch} loss: {epoch_loss}\")  \n",
        "\n",
        "\n",
        "            predicted, labels, val_loss = self.predict(val_loader, device)\n",
        "            if epoch==epochs: #last epoch\n",
        "                self.pred_labels_val=predicted.cpu().numpy()\n",
        "                self.real_labels_val=labels.cpu().numpy()\n",
        "            val_acc = predicted.eq(labels).sum().item() / len(predicted)\n",
        "            print(f\"epoch {epoch} val accuracy: {val_acc}\")\n",
        "            print(f\"epoch {epoch} val loss: {val_loss}\")\n",
        "\n",
        "            if val_acc > epoch_acc:\n",
        "                best_acc = val_acc\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), self.best_model_save_path)\n",
        "            \n",
        "            self.val_accuracy.append(val_acc)\n",
        "            self.val_loss.append(val_loss)\n",
        "        \n",
        "        self.pred_labels_train = torch.cat(self.pred_labels_train, dim=0)\n",
        "        self.real_labels_train = torch.cat(self.real_labels_train, dim=0)\n",
        "        self.pred_labels_train = self.pred_labels_train.cpu().numpy()\n",
        "        self.real_labels_train = self.real_labels_train.cpu().numpy()\n",
        "            \n",
        "            \n",
        "            \n",
        "        print(\"Finish!\")\n",
        "        \n",
        "        return best_acc, best_epoch\n",
        "            \n",
        "    def predict(self, test_loader, device):\n",
        "        self.eval()\n",
        "        labels = []\n",
        "        predicted = []\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "                spec, mfcc, chroma = batch_data\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                batch_label = batch_label.to(device)\n",
        "                \n",
        "                pred = self.forward(batch_data)\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted.append(pred_indices)\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                labels.append(batch_label)\n",
        "        val_loss /= len(test_loader)\n",
        "        predicted = torch.cat(predicted, dim=0)\n",
        "        labels = torch.cat(labels, dim=0)\n",
        "\n",
        "        return predicted, labels, val_loss\n",
        "    \n",
        "    def plot(self, which):\n",
        "        \n",
        "        X = [i for i in range(1, len(self.train_accuracy) + 1)]\n",
        "        if which=='train_loss':\n",
        "            y = self.train_loss\n",
        "        elif which=='train_acc':\n",
        "            y = self.train_accuracy\n",
        "        elif which=='val_acc':\n",
        "            y = self.val_accuracy\n",
        "        elif which=='val_loss':\n",
        "            y = self.val_loss\n",
        "        elif which=='confusion_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening)\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return        \n",
        "        elif which=='confusion_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening)\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return   \n",
        "            \n",
        "\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(which)\n",
        "        plt.title(which)\n",
        "        plt.plot(X, y, label=\"Train loss\")\n",
        "        plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeNet"
      ],
      "metadata": {
        "id": "r6ZfPlxFWXlH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWHZAY6hl7it"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self,input_channel, output_channel, kernel_size, stride=1, padding=0):\n",
        "        super(Block,self).__init__()\n",
        "\n",
        "        self.conv1=nn.Conv2d(input_channel,output_channel,kernel_size=kernel_size,padding=padding) # no stride\n",
        "        self.conv2=nn.Conv2d(output_channel,output_channel,kernel_size=kernel_size,stride=stride,padding=padding) # stride if down sampling\n",
        "        self.bn=nn.BatchNorm2d(output_channel)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "        self.layer=nn.Sequential(self.conv1, self.bn, self.relu, self.conv2, self.bn)\n",
        "\n",
        "        self.stride=stride\n",
        "        self.iden = nn.Conv2d(input_channel, output_channel, kernel_size=(1,1), stride=1)\n",
        "        if input_channel==64:\n",
        "            self.iden = nn.Conv2d(input_channel, output_channel, kernel_size=(1,1), stride=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        y = self.layer(x)\n",
        "        if self.stride==1: # stride==2 인 경우는 downsampling 구간이기 때문에 residual 안함\n",
        "            y = y + self.iden(x)\n",
        "        y = self.relu(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDKdmrW2l7iv"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self,data_type=\"mfcc\",method=\"origin\",best_model_save_path=\"./LeNet_best_model.pt\"):\n",
        "        super(LeNet,self).__init__()\n",
        "        \n",
        "        self.best_model_save_path = best_model_save_path\n",
        "        self.data_type=data_type\n",
        "        self.method=method\n",
        "\n",
        "        if data_type==\"mfcc\": # (1,100,501)\n",
        "            self.conv1=nn.Conv2d(1,64,kernel_size=(6,7),stride=2,padding=3)\n",
        "        elif data_type==\"spec\": #(1,201,501)\n",
        "            self.conv1=nn.Conv2d(1,64,kernel_size=(7,7),stride=2,padding=3)\n",
        "        elif data_type==\"chroma\": #(1,12,501)\n",
        "            self.conv1=nn.Conv2d(1,64,kernel_size=(6,7),stride=1,padding=3)\n",
        "        self.maxpool=nn.MaxPool2d(kernel_size=(3,3),stride=2,padding=1)\n",
        "        self.avgpool=nn.AdaptiveAvgPool2d((1,1)) # global avg pool\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "        self.seq1=nn.Sequential(self.conv1,self.relu,self.maxpool)  # (1,100,501)/(1,12,501)/(1,201,501) -> (64,51,251)/(1,13,251)/(1,101,251).conv -> (64,25,126)/(64,7,126)/(64,51,126).maxpool\n",
        "        self.seq2=nn.Sequential(Block(64,64,(3,3),padding=1),Block(64,64,(3,3),padding=1),Block(64,128,(3,4),stride=2,padding=1)) # (64,25,126) -> (64,25,126).block -> (64,25,126).block -> (128,13,63)/(128,4,63)/(128,26,63).block \n",
        "        if data_type==\"mfcc\":\n",
        "            self.seq3=nn.Sequential(Block(128,128,(3,3),padding=1),Block(128,128,(3,3),padding=1),Block(128,256,(3,3),stride=2,padding=1)) # (128,13,63) -> (128,13,63).block -> (128,13,63).block -> (256,7,32).block \n",
        "        elif data_type==\"spec\":\n",
        "            self.seq3=nn.Sequential(Block(128,128,(3,3),padding=1),Block(128,128,(3,3),padding=1),Block(128,256,(4,3),stride=2,padding=1)) # (128,26,63) -> ... -> (256,12,32).block \n",
        "        elif data_type==\"chroma\":\n",
        "            self.seq3=nn.Sequential(Block(128,128,(3,3),padding=1),Block(128,128,(3,3),padding=1),Block(128,256,(2,3),stride=2,padding=1)) # (128,4,63)/(128,26,63) -> ... -> (256,2,32)/(256,13,32).block \n",
        "        self.seq4=nn.Sequential(Block(256,256,(3,3),padding=1),Block(256,256,(3,3),padding=1),self.avgpool) # ... -> (256,1,1).avgpool\n",
        "\n",
        "        if self.method==\"multimodal\":\n",
        "            self.fc=nn.Linear(256,256)\n",
        "        if self.method==\"origin\":\n",
        "            self.fc=nn.Linear(256,5)\n",
        "            self.loss=nn.CrossEntropyLoss()\n",
        "            self.optimizer=optim.Adam(self.parameters(),lr=0.0001)\n",
        "\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def forward(self,x):       \n",
        "        y=self.seq1(x)\n",
        "        y=self.seq2(y)\n",
        "        y=self.seq3(y)\n",
        "        y=self.seq4(y)\n",
        "        y=y.view(y.shape[0],-1)\n",
        "        y=self.fc(y)\n",
        "        return y\n",
        "\n",
        "    def train_(self, train_loader, val_loader, learning_rate, epochs, device):\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "        self.pred_labels_train = []\n",
        "        self.real_labels_train = []\n",
        "        self.pred_labels_val = None\n",
        "        self.real_labels_val = None\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        self.loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "        best_epoch = -1\n",
        "        best_acc = -1 \n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            start_time = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            epoch_acc = 0.0\n",
        "            self.train()\n",
        "\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(train_loader)):\n",
        "                \n",
        "                spec, mfcc, chroma = batch_data\n",
        "\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                \n",
        "                batch_label = batch_label.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                pred = self.forward(batch_data) # (batch_size, 5)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                total += batch_data.shape[0]\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                correct += pred_indices.eq(batch_label).sum().item()\n",
        "                \n",
        "                if epoch==epochs: #last epoch\n",
        "                    self.pred_labels_train.append(pred_indices)\n",
        "                    self.real_labels_train.append(batch_label)\n",
        "                #for p, l in zip(pred_indices, batch_label):\n",
        "                #    print(f\"predicted: {index2region[p.item()]} real:{index2region[l.item()]}\")\n",
        "            \n",
        "            end_time = time.time()\n",
        "            print(f\"epoch {epoch} time: {end_time-start_time}sec(s).\")\n",
        "            \n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            epoch_acc = correct / total\n",
        "            self.train_accuracy.append(epoch_acc)\n",
        "            print(f\"epoch {epoch} train accuracy: {epoch_acc}\")\n",
        "            print(f\"epoch {epoch} loss: {epoch_loss}\")  \n",
        "\n",
        "\n",
        "            predicted, labels, val_loss = self.predict(val_loader, device)\n",
        "            if epoch==epochs: #last epoch\n",
        "                self.pred_labels_val=predicted.cpu().numpy()\n",
        "                self.real_labels_val=labels.cpu().numpy()\n",
        "            val_acc = predicted.eq(labels).sum().item() / len(predicted)\n",
        "            print(f\"epoch {epoch} val accuracy: {val_acc}\")\n",
        "            print(f\"epoch {epoch} val loss: {val_loss}\")\n",
        "\n",
        "            if val_acc > epoch_acc:\n",
        "                best_acc = val_acc\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), self.best_model_save_path)\n",
        "            \n",
        "            self.val_accuracy.append(val_acc)\n",
        "            self.val_loss.append(val_loss)\n",
        "        \n",
        "        self.pred_labels_train = torch.cat(self.pred_labels_train, dim=0)\n",
        "        self.real_labels_train = torch.cat(self.real_labels_train, dim=0)\n",
        "        self.pred_labels_train = self.pred_labels_train.cpu().numpy()\n",
        "        self.real_labels_train = self.real_labels_train.cpu().numpy()\n",
        "            \n",
        "            \n",
        "            \n",
        "        print(\"Finish!\")\n",
        "        \n",
        "        return best_acc, best_epoch\n",
        "            \n",
        "    def predict(self, test_loader, device):\n",
        "        self.eval()\n",
        "        labels = []\n",
        "        predicted = []\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "                spec, mfcc, chroma = batch_data\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                batch_label = batch_label.to(device)\n",
        "                \n",
        "                pred = self.forward(batch_data)\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted.append(pred_indices)\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                labels.append(batch_label)\n",
        "        val_loss /= len(test_loader)\n",
        "        predicted = torch.cat(predicted, dim=0)\n",
        "        labels = torch.cat(labels, dim=0)\n",
        "\n",
        "        return predicted, labels, val_loss\n",
        "    \n",
        "    def plot(self, which):\n",
        "        \n",
        "        X = [i for i in range(1, len(self.train_accuracy) + 1)]\n",
        "        if which=='train_loss':\n",
        "            y = self.train_loss\n",
        "        elif which=='train_acc':\n",
        "            y = self.train_accuracy\n",
        "        elif which=='val_acc':\n",
        "            y = self.val_accuracy\n",
        "        elif which=='val_loss':\n",
        "            y = self.val_loss\n",
        "        elif which=='confusion_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening)\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return        \n",
        "        elif which=='confusion_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening)\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return   \n",
        "            \n",
        "\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(which)\n",
        "        plt.title(which)\n",
        "        plt.plot(X, y, label=\"Train loss\")\n",
        "        plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "AfQWfeGGbkBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self,data_type=\"mfcc\",method=\"origin\",best_model_save_path=\"./LSTM_best_model.pt\"):\n",
        "        super(LSTM,self).__init__()\n",
        "\n",
        "        self.best_model_save_path=best_model_save_path\n",
        "        self.data_type=data_type\n",
        "        self.method=method\n",
        "\n",
        "        self.hidden_size=64\n",
        "        self.num_layers=1\n",
        "        if self.data_type==\"mfcc\":\n",
        "            self.input_size=100  #mfcc 기준\n",
        "        elif self.data_type==\"spec\":\n",
        "            self.input_size=201  #mfcc 기준\n",
        "        elif self.data_type==\"chroma\":\n",
        "            self.input_size=12  #mfcc 기준\n",
        "\n",
        "        self.lstm=nn.LSTM(input_size=self.input_size,hidden_size=self.hidden_size, num_layers =self.num_layers,batch_first=True)\n",
        "        \n",
        "        if self.method==\"multimodal\":\n",
        "            self.linear=nn.Linear(32064,256) # 밑에 forward에서 y.reshape 부분 보면 이해됨.  hidden -> 256 output vector for multimodal \n",
        "        elif self.method==\"origin\":\n",
        "            self.linear=nn.Linear(32064,5) # hidden -> 지역 개수\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.reshape(x.shape[0],-1,x.shape[3]) # 32,100,501 = (batch size, 100, 501)\n",
        "        x = x.view(x.shape[0],x.shape[2],-1) # 32,501,100 = (batch size, sequence len, input size)\n",
        "        \n",
        "        #Initial hidden state\n",
        "        h_0 = torch.zeros((self.num_layers, x.shape[0], self.hidden_size)).to(device=device)\n",
        "        #Initial cell state\n",
        "        c_0 = torch.zeros((self.num_layers, x.shape[0], self.hidden_size)).to(device=device)\n",
        "        \n",
        "        y, (h_n,c_n) =self.lstm(x,(h_0,c_0))\n",
        "        y = y.reshape(y.shape[0],-1) # y = (batch size, sequence len * hidden_size) = (32, 501*64) \n",
        "        y = self.linear(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def train_(self, train_loader, val_loader, learning_rate, epochs, device):\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "        self.pred_labels_train = []\n",
        "        self.real_labels_train = []\n",
        "        self.pred_labels_val = None\n",
        "        self.real_labels_val = None\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        self.loss_f=nn.CrossEntropyLoss()\n",
        "\n",
        "        best_epoch = -1\n",
        "        best_acc = -1 \n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            start_time = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            epoch_acc = 0.0\n",
        "            self.train()\n",
        "\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(train_loader)):\n",
        "                \n",
        "                spec, mfcc, chroma = batch_data\n",
        "\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                \n",
        "                batch_label = batch_label.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                pred = self.forward(batch_data) # (batch_size, 5)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                total += batch_data.shape[0]\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                correct += pred_indices.eq(batch_label).sum().item()\n",
        "                \n",
        "                if epoch==epochs: #last epoch\n",
        "                    self.pred_labels_train.append(pred_indices)\n",
        "                    self.real_labels_train.append(batch_label)\n",
        "                #for p, l in zip(pred_indices, batch_label):\n",
        "                #    print(f\"predicted: {index2region[p.item()]} real:{index2region[l.item()]}\")\n",
        "            \n",
        "            end_time = time.time()\n",
        "            print(f\"epoch {epoch} time: {end_time-start_time}sec(s).\")\n",
        "            \n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            epoch_acc = correct / total\n",
        "            self.train_accuracy.append(epoch_acc)\n",
        "            print(f\"epoch {epoch} train accuracy: {epoch_acc}\")\n",
        "            print(f\"epoch {epoch} loss: {epoch_loss}\")  \n",
        "\n",
        "\n",
        "            predicted, labels, val_loss = self.predict(val_loader, device)\n",
        "            if epoch==epochs: #last epoch\n",
        "                self.pred_labels_val=predicted.cpu().numpy()\n",
        "                self.real_labels_val=labels.cpu().numpy()\n",
        "            val_acc = predicted.eq(labels).sum().item() / len(predicted)\n",
        "            print(f\"epoch {epoch} val accuracy: {val_acc}\")\n",
        "            print(f\"epoch {epoch} val loss: {val_loss}\")\n",
        "\n",
        "            if val_acc > epoch_acc:\n",
        "                best_acc = val_acc\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), self.best_model_save_path)\n",
        "            \n",
        "            self.val_accuracy.append(val_acc)\n",
        "            self.val_loss.append(val_loss)\n",
        "        \n",
        "        self.pred_labels_train = torch.cat(self.pred_labels_train, dim=0)\n",
        "        self.real_labels_train = torch.cat(self.real_labels_train, dim=0)\n",
        "        self.pred_labels_train = self.pred_labels_train.cpu().numpy()\n",
        "        self.real_labels_train = self.real_labels_train.cpu().numpy()\n",
        "            \n",
        "            \n",
        "            \n",
        "        print(\"Finish!\")\n",
        "        \n",
        "        return best_acc, best_epoch\n",
        "            \n",
        "    def predict(self, test_loader, device):\n",
        "        self.eval()\n",
        "        labels = []\n",
        "        predicted = []\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "                spec, mfcc, chroma = batch_data\n",
        "                if self.data_type==\"mfcc\":\n",
        "                    batch_data=mfcc.to(device)\n",
        "                elif self.data_type==\"spec\":\n",
        "                    batch_data=spec.to(device)\n",
        "                elif self.data_type==\"chroma\":\n",
        "                    batch_data=chroma.to(device)\n",
        "                batch_label = batch_label.to(device)\n",
        "                \n",
        "                pred = self.forward(batch_data)\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted.append(pred_indices)\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                labels.append(batch_label)\n",
        "        val_loss /= len(test_loader)\n",
        "        predicted = torch.cat(predicted, dim=0)\n",
        "        labels = torch.cat(labels, dim=0)\n",
        "\n",
        "        return predicted, labels, val_loss\n",
        "    \n",
        "    def plot(self, which):\n",
        "        \n",
        "        X = [i for i in range(1, len(self.train_accuracy) + 1)]\n",
        "        if which=='train_loss':\n",
        "            y = self.train_loss\n",
        "        elif which=='train_acc':\n",
        "            y = self.train_accuracy\n",
        "        elif which=='val_acc':\n",
        "            y = self.val_accuracy\n",
        "        elif which=='val_loss':\n",
        "            y = self.val_loss\n",
        "        elif which=='confusion_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening)\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return        \n",
        "        elif which=='confusion_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening)\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "            plt.show()    \n",
        "            return   \n",
        "            \n",
        "\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(which)\n",
        "        plt.title(which)\n",
        "        plt.plot(X, y, label=\"Train loss\")\n",
        "        plt.savefig(f\"./result/LeNet_{which}_{self.data_type}.png\")\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xLwrziK4bl9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal"
      ],
      "metadata": {
        "id": "9teypfi5Wc12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCXmaYu6l7iw"
      },
      "outputs": [],
      "source": [
        "class MultiModalDialectClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_dim=1024, out_dim=5, method = \"ResNet\", best_model_save_path=\"./best_model.pt\"):\n",
        "        super(MultiModalDialectClassifier, self).__init__()\n",
        "\n",
        "        self.method = method\n",
        "        self.best_model_save_path = best_model_save_path\n",
        "        \n",
        "        if self.method==\"ResNet\"\n",
        "            self.spec_NN = ResNet18(1, model_type='spec')\n",
        "            self.mfcc_NN = ResNet18(1, model_type='mfcc')\n",
        "            self.chroma_NN = ResNet18(1, model_type='chroma')\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc1_resnet = nn.Linear(128*3, 128)\n",
        "        self.fc2_resnet = nn.Linear(128,out_dim)\n",
        "        self.lastlayer_resnet = nn.Sequential(self.fc1_resnet, self.relu, self.fc2_resnet)\n",
        "        \n",
        "        self.spec_lenet = LeNet(method=\"multimodal\",data_type=\"spec\")\n",
        "        self.mfcc_lenet = LeNet(method=\"multimodal\",data_type=\"mfcc\")\n",
        "        self.chroma_lenet = LeNet(method=\"multimodal\",data_type=\"chroma\")\n",
        "\n",
        "        self.fc1_lenet = nn.Linear(5*3, 10)\n",
        "        self.fc2_lenet = nn.Linear(10,out_dim)\n",
        "        self.lastlayer_lenet = nn.Sequential(self.fc1_lenet, self.relu, self.fc2_lenet)\n",
        "\n",
        "        self.loss_f = nn.CrossEntropyLoss()\n",
        "        self.optimizer = None\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        spec_x, mfcc_x, chroma_x = x\n",
        "\n",
        "        if self.method == \"ResNet\":\n",
        "            spec_y = self.spec_resnet(spec_x)\n",
        "            mfcc_y = self.mfcc_resnet(mfcc_x)\n",
        "            chroma_y = self.chroma_resnet(chroma_x)\n",
        "            y = torch.cat([spec_y, mfcc_y, chroma_y], dim=1)\n",
        "            y = y.view(y.shape[0], -1)\n",
        "        \n",
        "            y = self.lastlayer_resnet(y)\n",
        "\n",
        "        if self.method == \"LeNet\":\n",
        "            spec_y = self.spec_lenet(spec_x)\n",
        "            mfcc_y = self.mfcc_lenet(mfcc_x)\n",
        "            chroma_y = self.chroma_lenet(chroma_x)\n",
        "\n",
        "            y = torch.cat([spec_y, mfcc_y, chroma_y], dim=1)\n",
        "            y = y.view(y.shape[0], -1)\n",
        "        \n",
        "            y = self.lastlayer_lenet(y)\n",
        "\n",
        "        #y = self.softmax(y)\n",
        "        #print(y.shape)\n",
        "        return y\n",
        "    \n",
        "    def train_(self, train_loader, val_loader, learning_rate, epochs, device):\n",
        "        self.train_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_accuracy = []\n",
        "        self.val_loss = []\n",
        "        self.pred_labels_train = []\n",
        "        self.real_labels_train = []\n",
        "        self.pred_labels_val = None\n",
        "        self.real_labels_val = None\n",
        "\n",
        "        self.optimizer = optim.AdamW(self.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "        best_epoch = -1\n",
        "        best_acc = -1 \n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            start_time = time.time()\n",
        "            epoch_loss = 0.0\n",
        "            epoch_acc = 0.0\n",
        "            self.train()\n",
        "\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(train_loader)):\n",
        "                \n",
        "                spec, mfcc, chroma = batch_data\n",
        "                spec, mfcc, chroma = spec.to(device), mfcc.to(device), chroma.to(device)\n",
        "                batch_data = (spec, mfcc, chroma)\n",
        "                batch_label = batch_label.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                pred = self.forward(batch_data) # (batch_size, 5)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                total += batch_data[0].shape[0]\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                correct += pred_indices.eq(batch_label).sum().item()\n",
        "                \n",
        "                if epoch==epochs: #last epoch\n",
        "                    self.pred_labels_train.append(pred_indices)\n",
        "                    self.real_labels_train.append(batch_label)\n",
        "                #for p, l in zip(pred_indices, batch_label):\n",
        "                #    print(f\"predicted: {index2region[p.item()]} real:{index2region[l.item()]}\")\n",
        "            \n",
        "            end_time = time.time()\n",
        "            print(f\"epoch {epoch} time: {end_time-start_time}sec(s).\")\n",
        "            \n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            self.train_loss.append(epoch_loss)\n",
        "            epoch_acc = correct / total\n",
        "            self.train_accuracy.append(epoch_acc)\n",
        "            print(f\"epoch {epoch} train accuracy: {epoch_acc}\")\n",
        "            print(f\"epoch {epoch} loss: {epoch_loss}\")  \n",
        "\n",
        "\n",
        "            predicted, labels, val_loss = self.predict(val_loader, device)\n",
        "            if epoch==epochs: #last epoch\n",
        "                self.pred_labels_val=predicted.cpu().numpy()\n",
        "                self.real_labels_val=labels.cpu().numpy()\n",
        "            val_acc = predicted.eq(labels).sum().item() / len(predicted)\n",
        "            print(f\"epoch {epoch} val accuracy: {val_acc}\")\n",
        "            print(f\"epoch {epoch} val loss: {val_loss}\")\n",
        "\n",
        "            if val_acc > epoch_acc:\n",
        "                best_acc = val_acc\n",
        "                best_epoch = epoch\n",
        "                torch.save(self.state_dict(), self.best_model_save_path)\n",
        "            \n",
        "            self.val_accuracy.append(val_acc)\n",
        "            self.val_loss.append(val_loss)\n",
        "        \n",
        "        self.pred_labels_train = torch.cat(self.pred_labels_train, dim=0)\n",
        "        self.real_labels_train = torch.cat(self.real_labels_train, dim=0)\n",
        "        self.pred_labels_train = self.pred_labels_train.cpu().numpy()\n",
        "        self.real_labels_train = self.real_labels_train.cpu().numpy()\n",
        "            \n",
        "            \n",
        "            \n",
        "        print(\"Finish!\")\n",
        "        \n",
        "        return best_acc, best_epoch\n",
        "            \n",
        "    def predict(self, test_loader, device):\n",
        "        self.eval()\n",
        "        labels = []\n",
        "        predicted = []\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (batch_data, batch_label) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "                spec, mfcc, chroma = batch_data\n",
        "                spec, mfcc, chroma = spec.to(device), mfcc.to(device), chroma.to(device)\n",
        "                batch_data = (spec, mfcc, chroma)\n",
        "                batch_label = batch_label.to(device)\n",
        "                \n",
        "                pred = self.forward(batch_data)\n",
        "\n",
        "                _, pred_indices = torch.max(pred, axis=1)\n",
        "                loss = self.loss_f(pred, batch_label)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted.append(pred_indices)\n",
        "                batch_label = torch.max(batch_label, axis=1)[1]\n",
        "                labels.append(batch_label)\n",
        "        val_loss /= len(test_loader)\n",
        "        predicted = torch.cat(predicted, dim=0)\n",
        "        labels = torch.cat(labels, dim=0)\n",
        "\n",
        "        return predicted, labels, val_loss\n",
        "    \n",
        "    def plot(self, which):\n",
        "        \n",
        "        X = [i for i in range(1, len(self.train_accuracy) + 1)]\n",
        "        if which=='train_loss':\n",
        "            y = self.train_loss\n",
        "        elif which=='train_acc':\n",
        "            y = self.train_accuracy\n",
        "        elif which=='val_acc':\n",
        "            y = self.val_accuracy\n",
        "        elif which=='val_loss':\n",
        "            y = self.val_loss\n",
        "        elif which=='confusion_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening)\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/model_{which}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_train':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_train, self.pred_labels_train, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('train confusion matrix')\n",
        "            plt.savefig(f\"./result/model_{which}.png\")\n",
        "            plt.show()    \n",
        "            return        \n",
        "        elif which=='confusion_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening)\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/model_{which}.png\")\n",
        "            plt.show()\n",
        "            return\n",
        "        elif which=='confusion_normalize_val':\n",
        "            ConfusionMatrixDisplay.from_predictions(self.real_labels_val, self.pred_labels_val, display_labels=region_shortening, normalize='true')\n",
        "            plt.title('val confusion matrix')\n",
        "            plt.savefig(f\"./result/model_{which}.png\")\n",
        "            plt.show()    \n",
        "            return   \n",
        "            \n",
        "\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(which)\n",
        "        plt.title(which)\n",
        "        plt.plot(X, y, label=\"Train loss\")\n",
        "        plt.savefig(f\"./result/model_{which}.png\")\n",
        "        plt.show()\n",
        "\n",
        "    def getConvLayers(self, lenet):\n",
        "        weights = []\n",
        "        conv_layers = []\n",
        "        for i in range(len(lenet)):\n",
        "            if type(lenet[i]) == nn.Conv2d:\n",
        "                weights.append(lenet[i].weight)\n",
        "                conv_layers.append(lenet[i])\n",
        "            elif type(lenet[i]) == nn.Sequential:\n",
        "                for basic in lenet[i].children(): # basic block\n",
        "                    for in_basic in basic.children():\n",
        "                        if type(in_basic) == nn.Conv2d:\n",
        "                            weights.append(in_basic.weight)\n",
        "                            conv_layers.append(in_basic)\n",
        "                        if type(in_basic) == nn.Sequential:\n",
        "                            for in_basic_in_sequential in in_basic:\n",
        "                                if type(in_basic_in_sequential) == nn.Conv2d:\n",
        "                                    weights.append(in_basic_in_sequential.weight)\n",
        "                                    conv_layers.append(in_basic_in_sequential)            \n",
        "        return weights, conv_layers\n",
        "\n",
        "    def extractConvLayer(self):\n",
        "        children_ = list(self.children())\n",
        "        spec_lenet = list(children_[0].children())\n",
        "        mfcc_lenet = list(children_[1].children())\n",
        "        chroma_lenet = list(children_[2].children()) \n",
        "\n",
        "        spec_weights, spec_layers = self.getConvLayers(spec_lenet)\n",
        "        mfcc_weights, mfcc_layers = self.getConvLayers(mfcc_lenet)\n",
        "        chroma_weights, chroma_layers = self.getConvLayers(chroma_lenet)\n",
        "\n",
        "        self.spec_weights = spec_weights\n",
        "        self.spec_layers = spec_layers\n",
        "        self.mfcc_weights = mfcc_weights\n",
        "        self.mfcc_layers = mfcc_layers\n",
        "        self.chroma_weights = chroma_weights\n",
        "        self.chroma_layers = chroma_layers\n",
        "        \n",
        "        return spec_weights, spec_layers, mfcc_weights, mfcc_layers, chroma_weights, chroma_layers\n",
        "\n",
        "    def plotFilter(self, where='first', data_type='spec', when='before_train'):\n",
        "        if data_type == 'spec':\n",
        "            filters = self.spec_weights\n",
        "        elif data_type == 'mfcc':\n",
        "            filters = self.mfcc_weights\n",
        "        elif data_type == 'chroma':\n",
        "            filters = self.chroma_weights\n",
        "        x_len = 0\n",
        "        y_len = 0\n",
        "        if where=='first': # 64x1x7x7\n",
        "            filters = filters[0]\n",
        "            filters = filters[:,0,:,:]\n",
        "            plt.figure(figsize=(20,17))\n",
        "            x_len=8\n",
        "            y_len=8\n",
        "        elif where=='middle': # 128x64x3x3\n",
        "            filters = filters[16]\n",
        "            filters = filters[:,0,:,:]\n",
        "            plt.figure(figsize=(30,25))\n",
        "            x_len= 16\n",
        "            y_len= 8\n",
        "        elif where=='last': # 256x256x3x3\n",
        "            filters = filters[len(filters)-2]\n",
        "            filters = filters[:,0,:,:]\n",
        "            plt.figure(figsize=(40,32))\n",
        "            x_len=16\n",
        "            y_len=16\n",
        "        for i,filter in enumerate(filters):\n",
        "            plt.subplot(x_len, y_len, i+1)\n",
        "            plt.imshow(filter.detach().cpu(), cmap='gray')\n",
        "            plt.axis('off')\n",
        "        plt.savefig(f\"./result/{data_type}_filter_{where}_{when}.png\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    \n",
        "    def plotOriginalImage(self, data):\n",
        "        plt.imshow(data[0,:,:])\n",
        "        plt.show()\n",
        "\n",
        "    def plotFeatureMap(self, data, where='first', data_type='spec', when='before_train'):\n",
        "        if data_type == 'spec':\n",
        "            layers = self.spec_layers\n",
        "            x_len = 8\n",
        "            y_len = 8\n",
        "        elif data_type == 'mfcc':\n",
        "            layers = self.mfcc_layers\n",
        "            x_len = 16\n",
        "            y_len = 4\n",
        "        elif data_type == 'chroma':\n",
        "            layers = self.chroma_layers\n",
        "            x_len = 32\n",
        "            y_len = 2\n",
        "\n",
        "        if where=='first':\n",
        "            plt.figure(figsize=(20,17))\n",
        "            layer = layers[0]\n",
        "        elif where=='middle':\n",
        "            pass\n",
        "        elif where=='last':\n",
        "            pass\n",
        "        results = layer(data.to(device)) # 64x?x251\n",
        "        for i, result in enumerate(results):\n",
        "            plt.subplot(x_len, y_len, i+1)\n",
        "            plt.imshow(result.detach().cpu())\n",
        "            plt.axis('off')\n",
        "        plt.savefig(f\"./result/{data_type}_feature_map_{where}_{when}.png\")\n",
        "        plt.show()\n",
        "        plt.close()      \n",
        "\n",
        "        \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "6Mj7XC2YWGxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxbk9sOZl7i3"
      },
      "outputs": [],
      "source": [
        "def CV_Plot(title, arg, y):\n",
        "        X = [i for i in range(1, len(y) + 1)]\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(title)\n",
        "        plt.title(title)\n",
        "        plt.plot(X, y, label=title)\n",
        "        plt.savefig(f\"./result/model_{title}_{arg}.png\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjudM5pHl7i8"
      },
      "outputs": [],
      "source": [
        "def CrossValidation(dataset, learning_rate, epochs, device, method = \"ResNet\",data_type=\"mfcc\"):\n",
        "        hparams = []\n",
        "        for i in range(len(learning_rate)):\n",
        "            for j in range(len(epochs)):\n",
        "                hparams.append((learning_rate[i], epochs[j]))\n",
        "        print(hparams)\n",
        "\n",
        "        train_dataset_l = []\n",
        "        validation_dataset_l = []\n",
        "\n",
        "        kf = KFold(n_splits = 5, shuffle = True, random_state = 50)\n",
        "\n",
        "        for train_index, test_index in kf.split(train_dataset):\n",
        "            train_dataset_l.append(Subset(train_dataset,train_index))\n",
        "            validation_dataset_l.append(Subset(train_dataset,test_index))\n",
        "\n",
        "        result = []\n",
        "        for i in range(len(hparams)):\n",
        "            lr = hparams[i][0]\n",
        "            e = hparams[i][1]\n",
        "\n",
        "            print(f\"Learning rate : {lr}, Epochs : {e}\")\n",
        "\n",
        "            last_val_acc = []\n",
        "            for j in range(5):\n",
        "                print(f\"#{j+1} validation\")\n",
        "                if method==\"Multimodal_ResNet\"\n",
        "                    model = MultiModalDialectClassifier(method=\"ResNet\").to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"Multimodal_LeNet\"\n",
        "                    model = MultiModalDialectClassifier(method=\"LeNet\").to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"ResNet\"\n",
        "                    model = ResNet18(1,output_dim=5,model_type=data_type).to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"LeNet\"\n",
        "                    model = LeNet(data_type=data_type).to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                elif method==\"LSTM\"\n",
        "                    model = LSTM(data_type=data_type).to(device) # 매번 새로 정의해서 다시 학습해야함\n",
        "                train_loader = DataLoader(train_dataset_l[j], batch_size=32, shuffle=True)\n",
        "                validation_loader = DataLoader(validation_dataset_l[j], batch_size=32, shuffle=True)\n",
        "\n",
        "                model.train_(train_loader, validation_loader, lr, e, device)\n",
        "                last_val_acc.append(model.val_accuracy[-1])\n",
        "                    \n",
        "                # model.plot('train_acc')\n",
        "                # model.plot('val_acc')\n",
        "            result.append((np.array(last_val_acc)).mean())\n",
        "\n",
        "        idx = result.index(max(result))\n",
        "        best_lr, best_ep = hparams[idx]\n",
        "        print(f\"Best Learning Rate : {best_lr}, Best Epoch : {best_ep}\")\n",
        "\n",
        "        return best_lr, best_ep"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(dataset)*0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "SVJ-Td990E1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용법\n",
        "\n",
        "1. CrossValidation() 함수를 사용하여 테스트한다. 이 때 결정할 인자는 아래와 같다.\n",
        "2. method를 다음 중 결정한다. {\"ResNet\",\"LeNet\",\"LSTM\",\"Multimodal_ResNet\",\"Multimodal_LeNet\"}\n",
        "\n",
        "3. dat_type을 다음 중 결정한다. {\"spec\",\"mfcc\",\"chroma\"} -> multimodal은 모든 데이터를 사용하게끔 설계되어 있으므로 안 적어도 되고, 아무 데이터 타입을 적어도 상관없다."
      ],
      "metadata": {
        "id": "i5prxoHcu40h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxzmWo0Kl7i9",
        "outputId": "c143d9a3-dd2f-4db5-aec4-44d7746dcb11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.001, 15), (0.0005, 15), (0.0001, 15)]\n",
            "Learning rate : 0.0001, Epochs : 15\n",
            "#1 validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 time: 19.515663146972656sec(s).\n",
            "epoch 1 train accuracy: 0.69875\n",
            "epoch 1 loss: 0.951231119632721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 val accuracy: 0.255\n",
            "epoch 1 val loss: 2.683886326276339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 time: 19.79457950592041sec(s).\n",
            "epoch 2 train accuracy: 0.95\n",
            "epoch 2 loss: 0.24728955939412117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 val accuracy: 0.67\n",
            "epoch 2 val loss: 0.9466624122399551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 time: 19.365737676620483sec(s).\n",
            "epoch 3 train accuracy: 0.966875\n",
            "epoch 3 loss: 0.11268262706696987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 val accuracy: 0.985\n",
            "epoch 3 val loss: 0.07424391920749958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 time: 19.32786202430725sec(s).\n",
            "epoch 4 train accuracy: 0.989375\n",
            "epoch 4 loss: 0.05574384331703186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 val accuracy: 0.9425\n",
            "epoch 4 val loss: 0.14519856870174408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 time: 19.498624324798584sec(s).\n",
            "epoch 5 train accuracy: 0.99\n",
            "epoch 5 loss: 0.04978871935978532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 val accuracy: 0.9975\n",
            "epoch 5 val loss: 0.017396053335127924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 time: 19.54596757888794sec(s).\n",
            "epoch 6 train accuracy: 0.996875\n",
            "epoch 6 loss: 0.01780555442906916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 val accuracy: 0.95\n",
            "epoch 6 val loss: 0.1442633907382305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 time: 19.4309139251709sec(s).\n",
            "epoch 7 train accuracy: 0.9975\n",
            "epoch 7 loss: 0.013311601793393493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 val accuracy: 1.0\n",
            "epoch 7 val loss: 0.011773067705619793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 time: 19.364396810531616sec(s).\n",
            "epoch 8 train accuracy: 0.996875\n",
            "epoch 8 loss: 0.012168203915935009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 val accuracy: 0.985\n",
            "epoch 8 val loss: 0.039212265553382725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 time: 19.394173622131348sec(s).\n",
            "epoch 9 train accuracy: 1.0\n",
            "epoch 9 loss: 0.005739534478634596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 val accuracy: 0.995\n",
            "epoch 9 val loss: 0.012025574831148753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 time: 19.440505504608154sec(s).\n",
            "epoch 10 train accuracy: 0.995625\n",
            "epoch 10 loss: 0.013106236876337789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 val accuracy: 0.855\n",
            "epoch 10 val loss: 0.5937711344315455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 time: 19.45619535446167sec(s).\n",
            "epoch 11 train accuracy: 0.991875\n",
            "epoch 11 loss: 0.030395570260006933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 val accuracy: 0.8775\n",
            "epoch 11 val loss: 0.40211995862997496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 time: 19.420964002609253sec(s).\n",
            "epoch 12 train accuracy: 0.985625\n",
            "epoch 12 loss: 0.04589604350039735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 val accuracy: 0.895\n",
            "epoch 12 val loss: 0.2489442928479268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 time: 19.38740634918213sec(s).\n",
            "epoch 13 train accuracy: 0.990625\n",
            "epoch 13 loss: 0.029977972162887456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 val accuracy: 0.9825\n",
            "epoch 13 val loss: 0.04078947800175788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 time: 19.413176774978638sec(s).\n",
            "epoch 14 train accuracy: 0.995625\n",
            "epoch 14 loss: 0.020159632824361326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 val accuracy: 0.99\n",
            "epoch 14 val loss: 0.014155479519663809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 time: 19.393656015396118sec(s).\n",
            "epoch 15 train accuracy: 0.999375\n",
            "epoch 15 loss: 0.0042466492101084444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 val accuracy: 0.99\n",
            "epoch 15 val loss: 0.036103223978828355\n",
            "Finish!\n",
            "#2 validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 time: 19.450356483459473sec(s).\n",
            "epoch 1 train accuracy: 0.675\n",
            "epoch 1 loss: 1.0093259364366531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 val accuracy: 0.2225\n",
            "epoch 1 val loss: 3.185189962387085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 time: 19.434871673583984sec(s).\n",
            "epoch 2 train accuracy: 0.925625\n",
            "epoch 2 loss: 0.3000485087931156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 val accuracy: 0.36\n",
            "epoch 2 val loss: 1.9831223579553456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 time: 19.525851488113403sec(s).\n",
            "epoch 3 train accuracy: 0.97375\n",
            "epoch 3 loss: 0.11317611016333103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 val accuracy: 0.78\n",
            "epoch 3 val loss: 0.4944761578853314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 time: 19.50551462173462sec(s).\n",
            "epoch 4 train accuracy: 0.98625\n",
            "epoch 4 loss: 0.057984664048999546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 val accuracy: 0.9775\n",
            "epoch 4 val loss: 0.08347513755926719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 time: 19.405630826950073sec(s).\n",
            "epoch 5 train accuracy: 0.9925\n",
            "epoch 5 loss: 0.03440340627916157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 val accuracy: 0.97\n",
            "epoch 5 val loss: 0.06734184684375158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 time: 19.43099617958069sec(s).\n",
            "epoch 6 train accuracy: 0.99875\n",
            "epoch 6 loss: 0.017043355819769204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 val accuracy: 0.91\n",
            "epoch 6 val loss: 0.31492750203380215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 time: 19.428962469100952sec(s).\n",
            "epoch 7 train accuracy: 0.996875\n",
            "epoch 7 loss: 0.013389155869372189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 val accuracy: 0.8525\n",
            "epoch 7 val loss: 0.4616151343171413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 time: 19.444117546081543sec(s).\n",
            "epoch 8 train accuracy: 0.998125\n",
            "epoch 8 loss: 0.015185547019355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 val accuracy: 0.9825\n",
            "epoch 8 val loss: 0.05381891611390389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 time: 19.407727003097534sec(s).\n",
            "epoch 9 train accuracy: 0.99\n",
            "epoch 9 loss: 0.03661787353921682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 val accuracy: 0.8925\n",
            "epoch 9 val loss: 0.3577280227954571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 time: 19.502204418182373sec(s).\n",
            "epoch 10 train accuracy: 0.98875\n",
            "epoch 10 loss: 0.028555810645921154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 val accuracy: 0.855\n",
            "epoch 10 val loss: 0.40170835646299213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 time: 19.488821744918823sec(s).\n",
            "epoch 11 train accuracy: 0.9975\n",
            "epoch 11 loss: 0.014727623106446118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 val accuracy: 0.93\n",
            "epoch 11 val loss: 0.22570356554709947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 time: 19.488775491714478sec(s).\n",
            "epoch 12 train accuracy: 0.99625\n",
            "epoch 12 loss: 0.01146024110261351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 val accuracy: 0.985\n",
            "epoch 12 val loss: 0.06251388702255029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 time: 19.484333515167236sec(s).\n",
            "epoch 13 train accuracy: 0.996875\n",
            "epoch 13 loss: 0.01111790528986603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 val accuracy: 0.995\n",
            "epoch 13 val loss: 0.018005488001598187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 time: 19.49621272087097sec(s).\n",
            "epoch 14 train accuracy: 0.999375\n",
            "epoch 14 loss: 0.00313763161044335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 val accuracy: 0.97\n",
            "epoch 14 val loss: 0.06336939818440722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 time: 19.463099718093872sec(s).\n",
            "epoch 15 train accuracy: 0.998125\n",
            "epoch 15 loss: 0.00860650738584809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 val accuracy: 0.97\n",
            "epoch 15 val loss: 0.0743848088895902\n",
            "Finish!\n",
            "#3 validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 time: 19.446795225143433sec(s).\n",
            "epoch 1 train accuracy: 0.710625\n",
            "epoch 1 loss: 0.9431397819519043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 val accuracy: 0.195\n",
            "epoch 1 val loss: 2.4360956962292013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 time: 19.436033248901367sec(s).\n",
            "epoch 2 train accuracy: 0.951875\n",
            "epoch 2 loss: 0.21216485455632209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 val accuracy: 0.7225\n",
            "epoch 2 val loss: 0.5619961092105279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 time: 19.430379152297974sec(s).\n",
            "epoch 3 train accuracy: 0.98\n",
            "epoch 3 loss: 0.09175901487469673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 val accuracy: 0.9575\n",
            "epoch 3 val loss: 0.12197371572256088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 time: 19.43911075592041sec(s).\n",
            "epoch 4 train accuracy: 0.983125\n",
            "epoch 4 loss: 0.05866363633424044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 val accuracy: 0.775\n",
            "epoch 4 val loss: 0.6397013710095332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 time: 19.478731155395508sec(s).\n",
            "epoch 5 train accuracy: 0.985\n",
            "epoch 5 loss: 0.051233448199927804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 val accuracy: 0.815\n",
            "epoch 5 val loss: 0.5300365308156381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 time: 19.449608087539673sec(s).\n",
            "epoch 6 train accuracy: 0.991875\n",
            "epoch 6 loss: 0.030627917954698203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 val accuracy: 0.985\n",
            "epoch 6 val loss: 0.037869154618909724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 time: 19.44995427131653sec(s).\n",
            "epoch 7 train accuracy: 0.99875\n",
            "epoch 7 loss: 0.010987821351736784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 val accuracy: 0.9925\n",
            "epoch 7 val loss: 0.023768670713672273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 time: 19.477851390838623sec(s).\n",
            "epoch 8 train accuracy: 0.999375\n",
            "epoch 8 loss: 0.00761506368406117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 val accuracy: 0.9675\n",
            "epoch 8 val loss: 0.09650607066802107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 time: 19.482287645339966sec(s).\n",
            "epoch 9 train accuracy: 0.9975\n",
            "epoch 9 loss: 0.007999860974960029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 val accuracy: 0.9175\n",
            "epoch 9 val loss: 0.2675776252379784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 time: 19.468300819396973sec(s).\n",
            "epoch 10 train accuracy: 0.99625\n",
            "epoch 10 loss: 0.01614112496608868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 val accuracy: 0.6875\n",
            "epoch 10 val loss: 2.2033044008108287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 time: 19.464776515960693sec(s).\n",
            "epoch 11 train accuracy: 0.996875\n",
            "epoch 11 loss: 0.01352254286641255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 val accuracy: 0.9775\n",
            "epoch 11 val loss: 0.05709294461681006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 time: 19.463207960128784sec(s).\n",
            "epoch 12 train accuracy: 0.990625\n",
            "epoch 12 loss: 0.03416285324376076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 val accuracy: 0.97\n",
            "epoch 12 val loss: 0.11268248996482445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 time: 19.465895891189575sec(s).\n",
            "epoch 13 train accuracy: 0.98625\n",
            "epoch 13 loss: 0.03623605300672352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 val accuracy: 0.8525\n",
            "epoch 13 val loss: 0.42463822720142513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 time: 19.507241249084473sec(s).\n",
            "epoch 14 train accuracy: 0.996875\n",
            "epoch 14 loss: 0.012412288782652468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 val accuracy: 0.8825\n",
            "epoch 14 val loss: 0.3404146541769688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 time: 19.51024580001831sec(s).\n",
            "epoch 15 train accuracy: 0.998125\n",
            "epoch 15 loss: 0.008958808579482138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 val accuracy: 0.9925\n",
            "epoch 15 val loss: 0.016544462504008643\n",
            "Finish!\n",
            "#4 validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 time: 19.476829528808594sec(s).\n",
            "epoch 1 train accuracy: 0.698125\n",
            "epoch 1 loss: 0.9730232465267181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 val accuracy: 0.1925\n",
            "epoch 1 val loss: 2.0417134119914127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 time: 19.491068601608276sec(s).\n",
            "epoch 2 train accuracy: 0.92375\n",
            "epoch 2 loss: 0.3062076485157013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 val accuracy: 0.395\n",
            "epoch 2 val loss: 2.2259867649811964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 time: 19.467320203781128sec(s).\n",
            "epoch 3 train accuracy: 0.97375\n",
            "epoch 3 loss: 0.12364490918815135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 val accuracy: 0.7675\n",
            "epoch 3 val loss: 0.6557296147713294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 time: 19.54058027267456sec(s).\n",
            "epoch 4 train accuracy: 0.98875\n",
            "epoch 4 loss: 0.06814380574971438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 val accuracy: 0.9875\n",
            "epoch 4 val loss: 0.07887862923626716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 time: 19.495813608169556sec(s).\n",
            "epoch 5 train accuracy: 0.9975\n",
            "epoch 5 loss: 0.023115125428885223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 val accuracy: 0.9725\n",
            "epoch 5 val loss: 0.09365201426240113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 time: 19.498871564865112sec(s).\n",
            "epoch 6 train accuracy: 0.995625\n",
            "epoch 6 loss: 0.025707438522949815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 val accuracy: 0.9725\n",
            "epoch 6 val loss: 0.1128024196682068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 time: 19.55402159690857sec(s).\n",
            "epoch 7 train accuracy: 0.994375\n",
            "epoch 7 loss: 0.026400144239887596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 val accuracy: 0.935\n",
            "epoch 7 val loss: 0.1857290669129445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 time: 19.477907419204712sec(s).\n",
            "epoch 8 train accuracy: 0.989375\n",
            "epoch 8 loss: 0.03682161566335708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 val accuracy: 0.9325\n",
            "epoch 8 val loss: 0.1838283659173892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 time: 19.46212387084961sec(s).\n",
            "epoch 9 train accuracy: 0.99625\n",
            "epoch 9 loss: 0.012664621453732252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 val accuracy: 0.9925\n",
            "epoch 9 val loss: 0.02574358200833488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 time: 19.498080730438232sec(s).\n",
            "epoch 10 train accuracy: 1.0\n",
            "epoch 10 loss: 0.004653859648387879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 val accuracy: 0.995\n",
            "epoch 10 val loss: 0.011228352717947788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 time: 19.52420473098755sec(s).\n",
            "epoch 11 train accuracy: 1.0\n",
            "epoch 11 loss: 0.002149222237057984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 val accuracy: 0.995\n",
            "epoch 11 val loss: 0.012208959114594528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 time: 19.525471210479736sec(s).\n",
            "epoch 12 train accuracy: 1.0\n",
            "epoch 12 loss: 0.002778114425600506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 val accuracy: 0.995\n",
            "epoch 12 val loss: 0.023688171027550615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 time: 19.50728988647461sec(s).\n",
            "epoch 13 train accuracy: 1.0\n",
            "epoch 13 loss: 0.0014601725738612003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 val accuracy: 0.995\n",
            "epoch 13 val loss: 0.014020775344061594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 time: 19.52264094352722sec(s).\n",
            "epoch 14 train accuracy: 1.0\n",
            "epoch 14 loss: 0.0018448783172061666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 val accuracy: 0.9975\n",
            "epoch 14 val loss: 0.008192094223117098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 time: 19.543914794921875sec(s).\n",
            "epoch 15 train accuracy: 1.0\n",
            "epoch 15 loss: 0.0013585687466547824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 val accuracy: 0.995\n",
            "epoch 15 val loss: 0.014065027844760781\n",
            "Finish!\n",
            "#5 validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 time: 19.510453701019287sec(s).\n",
            "epoch 1 train accuracy: 0.715\n",
            "epoch 1 loss: 0.9377399128675461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 val accuracy: 0.165\n",
            "epoch 1 val loss: 2.4449292696439304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 time: 19.500438690185547sec(s).\n",
            "epoch 2 train accuracy: 0.950625\n",
            "epoch 2 loss: 0.22301914371550083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 val accuracy: 0.91\n",
            "epoch 2 val loss: 0.27079260234649366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 time: 19.499646186828613sec(s).\n",
            "epoch 3 train accuracy: 0.971875\n",
            "epoch 3 loss: 0.10079849779605865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 val accuracy: 0.665\n",
            "epoch 3 val loss: 0.8858812772310697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 time: 19.50833821296692sec(s).\n",
            "epoch 4 train accuracy: 0.98\n",
            "epoch 4 loss: 0.07827692616730929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 val accuracy: 0.54\n",
            "epoch 4 val loss: 1.3360215058693519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 time: 19.501092433929443sec(s).\n",
            "epoch 5 train accuracy: 0.989375\n",
            "epoch 5 loss: 0.04045665206387639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 val accuracy: 0.8825\n",
            "epoch 5 val loss: 0.3332167204756003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 time: 19.529765367507935sec(s).\n",
            "epoch 6 train accuracy: 0.986875\n",
            "epoch 6 loss: 0.04351671876851469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 val accuracy: 0.9125\n",
            "epoch 6 val loss: 0.24780980153725699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 time: 19.507490396499634sec(s).\n",
            "epoch 7 train accuracy: 0.991875\n",
            "epoch 7 loss: 0.024242606991901994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 val accuracy: 0.77\n",
            "epoch 7 val loss: 0.6446399436547205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 time: 19.514423608779907sec(s).\n",
            "epoch 8 train accuracy: 0.99625\n",
            "epoch 8 loss: 0.01517063362058252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 val accuracy: 0.9525\n",
            "epoch 8 val loss: 0.12932994016087973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 time: 19.52389907836914sec(s).\n",
            "epoch 9 train accuracy: 1.0\n",
            "epoch 9 loss: 0.0050661747192498295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 val accuracy: 0.9875\n",
            "epoch 9 val loss: 0.04159154535199587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 time: 19.509153842926025sec(s).\n",
            "epoch 10 train accuracy: 0.99875\n",
            "epoch 10 loss: 0.005035793014103547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 val accuracy: 0.9925\n",
            "epoch 10 val loss: 0.013889737928716036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 time: 19.5012047290802sec(s).\n",
            "epoch 11 train accuracy: 0.99625\n",
            "epoch 11 loss: 0.011244865437038242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 val accuracy: 0.775\n",
            "epoch 11 val loss: 0.8066369157571059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 time: 19.50662922859192sec(s).\n",
            "epoch 12 train accuracy: 0.996875\n",
            "epoch 12 loss: 0.012485704782884568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 val accuracy: 0.8875\n",
            "epoch 12 val loss: 0.3929000955361586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 time: 19.472636699676514sec(s).\n",
            "epoch 13 train accuracy: 0.9975\n",
            "epoch 13 loss: 0.009730043294257484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 val accuracy: 0.91\n",
            "epoch 13 val loss: 0.2579081259094752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 time: 19.49197506904602sec(s).\n",
            "epoch 14 train accuracy: 0.978125\n",
            "epoch 14 loss: 0.06573819097829983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 val accuracy: 0.705\n",
            "epoch 14 val loss: 1.2387986091467051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 time: 19.50408148765564sec(s).\n",
            "epoch 15 train accuracy: 0.995\n",
            "epoch 15 loss: 0.02490442062728107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  7.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 val accuracy: 0.405\n",
            "epoch 15 val loss: 3.84400252195505\n",
            "Finish!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "lr = [0.0001, 0.0005, 0.001]\n",
        "ep = [30]\n",
        "\n",
        "result = CrossValidation(train_dataset, learning_rate= lr, epochs= ep, device = device, method = \"ResNet\",data_type=\"mfcc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Val result"
      ],
      "metadata": {
        "id": "WbC5JhXX-ZoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "9NNgUuDI-WcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Train & Test(feat. Plot)"
      ],
      "metadata": {
        "id": "vqdXxM5p-cH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용법\n",
        "\n",
        "1. model_choose() 함수를 사용하여 model을 결정한다. 이 때 고려할 인자는 아래와 같다.\n",
        "2. method를 다음 중 결정한다. {\"ResNet\",\"LeNet\",\"LSTM\",\"Multimodal_ResNet\",\"Multimodal_LeNet\"}\n",
        "\n",
        "3. dat_type을 다음 중 결정한다. {\"spec\",\"mfcc\",\"chroma\"} -> multimodal은 모든 데이터를 사용하게끔 설계되어 있으므로 안 적어도 되고, 아무 데이터 타입을 적어도 상관없다."
      ],
      "metadata": {
        "id": "YuAHjrpdwGWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgWQR8irl7i-"
      },
      "outputs": [],
      "source": [
        "model=None\n",
        "\n",
        "def model_choose(model,method,data_type):\n",
        "    if method==\"Multimodal_ResNet\"\n",
        "        model = MultiModalDialectClassifier(method=\"ResNet\").to(device) \n",
        "    elif method==\"Multimodal\"\n",
        "        model = MultiModalDialectClassifier(method=\"LeNet\").to(device) \n",
        "    elif method==\"ResNet\"\n",
        "        model = ResNet18(1,output_dim=5,model_type=data_type).to(device) \n",
        "    elif method==\"LeNet\"\n",
        "        model = LeNet(data_type=data_type).to(device) \n",
        "    elif method==\"LSTM\"\n",
        "        model = LSTM(data_type=data_type).to(device) \n",
        "\n",
        "model_choose(model,\"Multimodal_ResNet\",\"mfcc\")\n",
        "\n",
        "spec_weights, spec_layers, mfcc_weights, mfcc_layers, chroma_weights, chroma_layers = model.extractConvLayer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f4qj5qEl7i_"
      },
      "outputs": [],
      "source": [
        "model.plotOriginalImage(dataset[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVGfNE65l7jA"
      },
      "outputs": [],
      "source": [
        "model.plotFilter(where='first', data_type='spec', when='before_train')\n",
        "model.plotFilter(where='middle', data_type='spec', when='before_train')\n",
        "model.plotFilter(where='last', data_type='spec', when='before_train')\n",
        "model.plotFilter(where='first', data_type='mfcc', when='before_train')\n",
        "model.plotFilter(where='middle', data_type='mfcc', when='before_train')\n",
        "model.plotFilter(where='last', data_type='mfcc', when='before_train')\n",
        "model.plotFilter(where='first', data_type='chroma', when='before_train')\n",
        "model.plotFilter(where='middle', data_type='chroma', when='before_train')\n",
        "model.plotFilter(where='last', data_type='chroma', when='before_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fejh8Zgl7jB"
      },
      "outputs": [],
      "source": [
        "model.plotFeatureMap(dataset[0][0][0], data_type='spec', when='before_train')\n",
        "model.plotFeatureMap(dataset[0][0][1], data_type='mfcc', when='before_train')\n",
        "model.plotFeatureMap(dataset[0][0][2], data_type='chroma', when='before_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KHzRCP7l7jC"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A2CcUpNl7jD"
      },
      "outputs": [],
      "source": [
        "model.train_(train_loader, test_loader, best_lr, 100, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Joa0Jjmdl7jD"
      },
      "outputs": [],
      "source": [
        "model.plot('train_acc')\n",
        "model.plot('train_loss')\n",
        "model.plot('val_acc')\n",
        "model.plot('val_loss')\n",
        "model.plot('confusion_train')\n",
        "model.plot('confusion_normalize_train')\n",
        "model.plot('confusion_val')\n",
        "model.plot('confusion_normalize_val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNs2T309l7jE"
      },
      "outputs": [],
      "source": [
        "spec_weights, spec_layers, mfcc_weights, mfcc_layers, chroma_weights, chroma_layers = model.extractConvLayer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9hNpM3Tl7jE"
      },
      "outputs": [],
      "source": [
        "model.plotFilter(where='first', data_type='spec', when='after_train')\n",
        "model.plotFilter(where='middle', data_type='spec', when='after_train')\n",
        "model.plotFilter(where='last', data_type='spec', when='after_train')\n",
        "model.plotFilter(where='first', data_type='mfcc', when='after_train')\n",
        "model.plotFilter(where='middle', data_type='mfcc', when='after_train')\n",
        "model.plotFilter(where='last', data_type='mfcc', when='after_train')\n",
        "model.plotFilter(where='first', data_type='chroma', when='after_train')\n",
        "model.plotFilter(where='middle', data_type='chroma', when='after_train')\n",
        "model.plotFilter(where='last', data_type='chroma', when='after_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nk2E_wyl7jF"
      },
      "outputs": [],
      "source": [
        "model.plotFeatureMap(dataset[0][0][0].to(device), data_type='spec', when='after_train')\n",
        "model.plotFeatureMap(dataset[0][0][1].to(device), data_type='mfcc', when='after_train')\n",
        "model.plotFeatureMap(dataset[0][0][2].to(device), data_type='chroma', when='after_train')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i7GkRqXfWRJn",
        "8hi2dX2fWVL2",
        "r6ZfPlxFWXlH",
        "AfQWfeGGbkBk",
        "9teypfi5Wc12",
        "6Mj7XC2YWGxA",
        "vqdXxM5p-cH_"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "2e21635c90e382193491c6c0b9d844d7654f1925e914d678f60b4feac832f05f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 64-bit ('env1_py37': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}